gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
# Q4.
# OECD
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
# non OECD
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
# Q5.
# assign quentile values
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
# Q4.
# OECD
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
# non OECD
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
# Q5.
# assign quentile values
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
z <- aggregate(Ranking~Income.Group,md, mean)
z <- aggregate(Ranking~Income.Group,md, mean)
md <- merge(gdp,edu,by.x=CountryCode, by.y=CountryCode) # nrow(md) = 189
library(plyr)
y <-arrange(md,desc(Ranking))
getwd()
source("run_analysis.R")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip",method="curl")
unzip(zipfile="./data/Dataset.zip",exdir="./data")
path_rf <- file.path("./data" , "UCI HAR Dataset")
files<-list.files(path_rf, recursive=TRUE)
files
dataActivityTest  <- read.table(file.path(path_rf, "test" , "Y_test.txt" ),header = FALSE)
dataActivityTrain <- read.table(file.path(path_rf, "train", "Y_train.txt"),header = FALSE)
dataSubjectTrain <- read.table(file.path(path_rf, "train", "subject_train.txt"),header = FALSE)
dataSubjectTest  <- read.table(file.path(path_rf, "test" , "subject_test.txt"),header = FALSE)
dataFeaturesTest  <- read.table(file.path(path_rf, "test" , "X_test.txt" ),header = FALSE)
dataFeaturesTrain <- read.table(file.path(path_rf, "train", "X_train.txt"),header = FALSE)
str(dataActivityTest)
library("plyr")
install.packages("plyr")
devtools::install_github("hadley/plyr")
install_github("hadley/plyr")
library("plyr")
library(plyr)
source("run_analysis.R")
source("data/run_analysis.R")
source("data\run_analysis.R")
source("data/run_analysis.R")
?file.path
filepath <-file.path("UCI HAR Dataset")
files<-list.files(path_rf, recursive=TRUE)
files
filepath <-file.path("UCI HAR Dataset")
files<-list.files(filepath, recursive=TRUE)
files
filepath <-file.path("./UCI HAR Dataset")
files<-list.files(filepath, recursive=TRUE)
files
getwd()
files <-list.files(filepath,recursive=TURE)
files <-list.files(filepath,recursive=TRUE)
filepath <- file.path("/","UCI HAR DataSet")
filepath
filepath <- file.path("/Getting and Cleaning Data","UCI HAR DataSet")
list.files(filepath,recursive = TRUE)
list.files("Getting and Cleaning Data/UCI HAR DataSet")
list.files("./UCI HAR DataSet")
list.files("../UCI HAR DataSet")
list.files("Getting and Cleaning Data/UCI HAR DataSet")
file.path("/Getting and Cleaning Data","UCI HAR DataSet")
path_rf <- file.path("/Getting and Cleaning Data","UCI HAR DataSet")
list.files(path_rf,recursive=TRUE)
path_rf <- file.path("Getting and Cleaning Data","UCI HAR DataSet")
list.files(path_rf,recursive=TRUE)
feature_file <- paste(path_rf, "/features.txt", sep = "")
feautre_file
feature_file
##Setting the directory path for needed files
path_rf <- file.path("Getting and Cleaning Data","UCI HAR DataSet")
feature_file <- paste(path_rf, "/features.txt", sep = "")
activity_labels_file <- paste(path_rf, "/activity_labels.txt", sep = "")
x_train_file <- paste(path_rf, "/train/X_train.txt", sep = "")
y_train_file <- paste(path_rf, "/train/y_train.txt", sep = "")
subject_train_file <- paste(path_rf, "/train/subject_train.txt", sep = "")
x_test_file  <- paste(path_rf, "/test/X_test.txt", sep = "")
y_test_file  <- paste(path_rf, "/test/y_test.txt", sep = "")
subject_test_file <- paste(path_rf, "/test/subject_test.txt", sep = "")
# Retrieve raw data
data_features <- read.table(feature_file, colClasses = c("character"))
data_activity_labels <- read.table(activity_labels_file, col.names = c("ActivityId", "Activity"))
data_x_train <- read.table(x_train_file)
data_y_train <- read.table(y_train_file)
data_subject_train <- read.table(subject_train_file)
data_x_test <- read.table(x_test_file)
data_y_test <- read.table(y_test_file)
data_subject_test <- read.table(subject_test_file)
#### 1 Merges the training and the test sets to create one data set.
##Binding the data
training_data <- cbind(cbind(data_x_train, data_subject_train), data_y_train)
test_data <- cbind(cbind(data_x_test, data_subject_test), data_y_test)
complete_data <- rbind(data_training_data, test_data)
##Column Labels
data_labels <- rbind(rbind(data_features, c(562, "Subject")), c(563, "ActivityId"))[,2]
names(complete_data) <- data_labels
complete_data <- rbind(training_data, test_data)
?paste
data_labels <- rbind(rbind(data_features, c(562, "Subject")), c(563, "ActivityId"))[,2]
names(complete_data) <- data_labels
head(complete_data)
strdata(complete_data)
str(complete_data)
?gsub
?make.names
data_mean_std <- complete_data[,grepl("mean|std|Subject|ActivityId", names(complete_data))]
data_mean_std
?grep
names(complete_data)
data_mean_std <- join(data_mean_std, data_activity_labels, by = "ActivityId", match = "first")
data_mean_std <- data_mean_std[,-1]
data_mean_std
# Remove parentheses
names(data_mean_std) <- gsub('\\(|\\)',"",names(data_mean_std), perl = TRUE)
# Make syntactically valid names
names(data_mean_std)  <- make.names(namesdata_mean_std))
# Make clearer names
names(data_mean_std)  <- gsub('Acc',"Acceleration",names(data_mean_std))
names(data_mean_std)  <- gsub('GyroJerk',"AngularAcceleration",names(data_mean_std))
names(data_mean_std)  <- gsub('Gyro',"AngularSpeed",names(data_mean_std))
names(data_mean_std)  <- gsub('Mag',"Magnitude",names(data_mean_std))
names(data_mean_std)  <- gsub('^t',"TimeDomain.",names(data_mean_std))
names(data_mean_std)  <- gsub('^f',"FrequencyDomain.",names(data_mean_std))
names(data_mean_std)  <- gsub('\\.mean',".Mean",names(data_mean_std))
names(data_mean_std)  <- gsub('\\.std',".StandardDeviation",names(data_mean_std))
names(data_mean_std)  <- gsub('Freq\\.',"Frequency.",names(data_mean_std))
names(data_mean_std)  <- gsub('Freq$',"Frequency",names(data_mean_std))
# Remove parentheses
names(data_mean_std) <- gsub('\\(|\\)',"",names(data_mean_std), perl = TRUE)
# Make syntactically valid names
names(data_mean_std)  <- make.names(names(data_mean_std))
# Make clearer names
names(data_mean_std)  <- gsub('Acc',"Acceleration",names(data_mean_std))
names(data_mean_std)  <- gsub('GyroJerk',"AngularAcceleration",names(data_mean_std))
names(data_mean_std)  <- gsub('Gyro',"AngularSpeed",names(data_mean_std))
names(data_mean_std)  <- gsub('Mag',"Magnitude",names(data_mean_std))
names(data_mean_std)  <- gsub('^t',"TimeDomain.",names(data_mean_std))
names(data_mean_std)  <- gsub('^f',"FrequencyDomain.",names(data_mean_std))
names(data_mean_std)  <- gsub('\\.mean',".Mean",names(data_mean_std))
names(data_mean_std)  <- gsub('\\.std',".StandardDeviation",names(data_mean_std))
names(data_mean_std)  <- gsub('Freq\\.',"Frequency.",names(data_mean_std))
names(data_mean_std)  <- gsub('Freq$',"Frequency",names(data_mean_std))
data_mean_std
View(data_mean_std)
View(data_mean_std)
View(complete_data)
View(complete_data)
View(data_activity_labels)
View(data_activity_labels)
View(data_features)
View(data_features)
source("run_anlaysis.R")
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
?grep
source("run_analysis.R")
library(httr)
direccion <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv "
archivo <- "ss06hid.csv"
download.file(direccion, archivo, method="curl")
direccion2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf"
archivo2 <- "PUMSDataDict06.pdf"
download.file(direccion2, archivo2, method="curl")
data <- read.table("ss06hid.csv", header = TRUE, sep = ",")
x <- names(data)
y <- strsplit(x, "wgtp")
y[123]
library(data.table)
direccion3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
archivo3 <- "GDP.csv"
download.file(direccion3, archivo3, method="curl")
GDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 191))
GDP <- GDP[X != ""]
GDP <- GDP[, list(X, X.1, X.3, X.4)]
setnames(GDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "GDP"))
columnagdp <- as.numeric(gsub(",", "", GDP$GDP))
mean(columnagdp, na.rm = TRUE)
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
read.csv(path2csv,stringsAsFactors=FALSE)
mydf <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran,package=="swirl")
filter(cran,r_version=="3.1.1",countr=="US")
filter(cran,r_version=="3.1.1",country=="US")
?Comparison
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="US"|country="IN")
filter(cran,country=="US"|country=="IN")
filter(cran,size>100500 & r_os="linux-gnu")
filter(cran,size>100500 & r_os=="linux-gnu")
filter(cran,size>100500,r_os=="linux-gnu")
is.na(c(3,5,nA,10))
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2 <-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran,country,desc(r_version),ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3 <-select(cran,ip_id:size)
cran3 <-select(cran,ip_id,size)
cran3 <-select(cran,ip_id,package,size)
cran3
mutate(cran3,siz_mb=size/2^20)
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10,correct_size=size-1000)
mutate(cran3,correct_zie=size+1000)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10,correct_size=size+1000)
mutate(cran3,correct_size=size-1000,size_mb=correct_size/2^20,size_gb=correct_size_mb/2^10,)
mutate(cran3,correct_size=size-1000,size_mb=correct_size/2^20,size_gb=correct_size/2^10,)
mutate(cran3,size,correct_size=size+1000,size_mb=correct_size/2^20,size_gb=correct_size/2^10,)
info()
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
group_by(package)
?group_by
by_package <- group_by(cran,package)
by_package
summarize(by_package)
summarize(by_package,mean(size))
?n_distinct
?n
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum,unique>465)
View(top_unique)
top_unique_sorted <- arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
gather(students2,sex_class,count,-grade)
res <- gather(students2,sex_class,count,-grade)
res
?separate
separate(res,col=sex_class, into=c("sex","class"))
submit()
students3
?gather
submit()
submit()
submit()
?spread
?spread
submit()
submit()
extrxt_numeric("class5")
extract_numeric("class5")
submit()
?mutate
?extract_numeric
submit()
submit()
?mutate
submit()
reset()
?mutate
?extract_numeric
class1 <- c("class1")
extract_numer(class1)
extract_numeric(class1)
extract_numeric(class1)
submit()
submit()
students3
mutate(students3,extract_numeric(class1))
mutate(students3,class1 = extract_numeric(class1))
mutate(students3,class1 = extract_numeric(students3$class1))
submit("script3.R")
submit()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
mutate(class = extract_numeric(class))
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade)
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade)  %>%
mutate(class = extract_numeric(class))
submit()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade)  %>%
mutate(class = extract_numeric(class))
submit()
submit()
students4
submit()
?unique
submit()
submit()
passed
failed
mutate(passed,status="passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
?bind_rows
bind_rows(passed,failed)
sat
bye()
swirl()
?contains
?select
?separate
submit()
submit()
select(sat,-contains("total"))
sat_ <- select(sat,-contains("total"))
gather(sat,part_sex,count,-score_range)
sat_ <- gather(sat,part_sex,count,-score_range)
separate(sat_,part_sex,into=c("part","sex"))
submit()
bye()
swirl()
submit()
reset()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
this_day = today()
this_day <- today()
this_day
year(this_da)
year(this_day)
wday(this_day)
wday(this_day,label=TRUE)
this_moment <- now()
this_moment
second(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
ymd("March 12, 1975")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1-9-2012")
ymd("--192012")
ymd("192012--")
mdy("1/9/2012")
ydm("2012/1/9")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment,now())
this_moment <- update(this_moment,hours =10, minutes=16,seconds =0)
this_moment
?now
nyc=now("America/New_York")
nyc<-now("America/New_York")
nyc
nyc + days(2)
depart <- nyc + days(2)
depart
depart <- update(depart,hours =17, minutes=34,seconds =0)
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- update(depart,hours =15,minutes=50)
arrive <- depart + hours(15) + minutes(50)
?with_tx
?with_tz
arrive <- with_tz(arrive,tzone="Asia/Hong_Kong")
arrive
last_time <- with_tz(mdy("June 17, 2008"),tzone="Singapore")
mdy("June 17, 2008", tz = "Singapore")
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
source("plot1.R")
source("ExData_Plotting1\plot1.R")
source("ExData_Plotting1/plot1.R")
getwd()
setwd("/Users/nina.cantutay/Documents/Data Science/ExData_Plotting1")
getwd()
source("plot1.R")
source(plot1.R)
source("plot1.r")
## Loading dataset
file <- "./household_power_consumption.txt"
data <- read.table(file, header = TRUE,sep = ";",
colClasses = c("character", "character", rep("numeric",7)),
na = "?")
## Data for two days are needed (Feb 1 and 2, 2007).
subsetdata <- data$Date == "1/2/2007" | data$Date == "2/2/2007"
neededData <- data[subsetdata, ]
x <- paste(neededData$Date, neededData$Time)
neededData$DateTime <- strptime(x, "%d/%m/%Y %H:%M:%S")
rownames(neededData) <- 1:nrow(neededData)
##Ploting plot1.png
png(filename = "plot1.png",
width = 480, height = 480,
units = "px", bg = "white")
hist(neededData$Global_active_power,
col = "red",
main = "Global Active Power",
xlab = "Global Active Power (kilowatts)",
breaks = 12, ylim = c(0, 1200))
dev.off()
source("plot1.r")
source("plot2.r")
source("plot3.r")
source("plot4.r")
